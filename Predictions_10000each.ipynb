{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_stars</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>user_useful</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>business_review_count</th>\n",
       "      <th>unigram</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v0i_UHJMo_hPBq9bxWvW4w</td>\n",
       "      <td>4.67</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1953</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vkVSCC7xljjrAI4UGfnKEQ</td>\n",
       "      <td>4.67</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n6QzIUObkYshz4dz2QRJTw</td>\n",
       "      <td>4.67</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MV3CcKScW05u5LVfF6ok0g</td>\n",
       "      <td>4.67</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IXvOzsEMYtiJI0CARmj77Q</td>\n",
       "      <td>4.67</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>61</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L_9BTb55X0GDtThi6GlZ6w</td>\n",
       "      <td>4.67</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>397</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HRPm3vEZ_F-33TYVT7Pebw</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>38</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ymAUG8DZfQcFTBSOiaNN4w</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8UIishPUD92hXtScSga_gw</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>w41ZS9shepfO3uEyhXEWuQ</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.5</td>\n",
       "      <td>251</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WF_QTN3p-thD74hqpp2j-Q</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PIsUSmvaUWB00qv5KTF1xA</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.5</td>\n",
       "      <td>35</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PdZ_uFjbbkjtm3SCY_KrZw</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.5</td>\n",
       "      <td>76</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>x5oV6wm9_Pb1QQ6jkjDjwQ</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lsoSqIrrDbQvWpMvsSj2xw</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1184</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23eqwlZzCWZkADWfd9atZw</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>48</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FunI9om-aK5oMIIJmhMlZA</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1953</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FKu4iU62EmWT6GZXPJ2sgA</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xdu8nXrbNKeaywCX79KZSw</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.5</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>K7o5jDInfmX3cY5oH6ATNw</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>418</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WYDFJOBOl7cycd7gN-c_xA</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.0</td>\n",
       "      <td>759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HSR2RLOifd0cvSNVqGXkMQ</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.5</td>\n",
       "      <td>259</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Kki2nwtP8U2qmWwRvPwLRA</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Q-mhDIKa3wJuWEx9uuciIA</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.5</td>\n",
       "      <td>47</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ypjtMQLKdAwKGRS-KU7oxA</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>vr9YpzkaVdDIauxiZYZhqA</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.5</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ia-w-nR1FrlzsiuEiqqlbg</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.5</td>\n",
       "      <td>58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>y21Fom8a_SdAyC6I0v554w</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>_ku1sDwkmQo2wIgWAaluZw</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>511</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Enuk_DJbK0JPmgbFU8ePKw</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>973</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>iYlepMJ6j4whB8gxiZm6mw</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>reeZj98t_X1DrZgQgFs9Kg</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>z9e32TaBomM5uY7fHYqYKg</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>2.5</td>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rQgIiq1FJR8NwBJuWlUn7Q</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>162</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7GsVl-wMaSfG1VoEK6-s6g</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>zEDdYhDYYfvd8bSQqpc_ww</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>b1Volwlw8gt_IGh9PhRQmw</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>iFL5Iw972vd09fg87ElP9A</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>53</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>pREKh8GSMq5UY9CqsnlQUQ</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DcON7DHHHsvl8fByRl41MQ</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.5</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>sny_ekbd4i_1EBx1gwayXw</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Tv-_7d1sa-6cPTZ20exTLA</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>76</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>uwp2sAXf5shT1ynRWo7sHg</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.5</td>\n",
       "      <td>73</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>gDBVb6Qdg5VAr2L95NEeFw</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.5</td>\n",
       "      <td>34</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ebggx4Zlc4VWReJMG1nT6w</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>2.5</td>\n",
       "      <td>94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Q0j8DFqW_zWNa-H1QuuPgg</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.0</td>\n",
       "      <td>194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>EKAN4jw3LsE3631feSaA_g</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>443</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>51TLGhFncBnppaBN5vHlcw</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>zo84NPvoDgm1W9poSCjPQQ</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.5</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0wsN8ZT101c8LhqwQZJjvw</td>\n",
       "      <td>3.62</td>\n",
       "      <td>359</td>\n",
       "      <td>79</td>\n",
       "      <td>3.5</td>\n",
       "      <td>37</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 review_id  user_stars  user_review_count  user_useful  \\\n",
       "0   v0i_UHJMo_hPBq9bxWvW4w        4.67                  6            0   \n",
       "1   vkVSCC7xljjrAI4UGfnKEQ        4.67                  6            0   \n",
       "2   n6QzIUObkYshz4dz2QRJTw        4.67                  6            0   \n",
       "3   MV3CcKScW05u5LVfF6ok0g        4.67                  6            0   \n",
       "4   IXvOzsEMYtiJI0CARmj77Q        4.67                  6            0   \n",
       "5   L_9BTb55X0GDtThi6GlZ6w        4.67                  6            0   \n",
       "6   HRPm3vEZ_F-33TYVT7Pebw        5.00                  1            0   \n",
       "7   ymAUG8DZfQcFTBSOiaNN4w        3.62                359           79   \n",
       "8   8UIishPUD92hXtScSga_gw        3.62                359           79   \n",
       "9   w41ZS9shepfO3uEyhXEWuQ        3.62                359           79   \n",
       "10  WF_QTN3p-thD74hqpp2j-Q        3.62                359           79   \n",
       "11  PIsUSmvaUWB00qv5KTF1xA        3.62                359           79   \n",
       "12  PdZ_uFjbbkjtm3SCY_KrZw        3.62                359           79   \n",
       "13  x5oV6wm9_Pb1QQ6jkjDjwQ        3.62                359           79   \n",
       "14  lsoSqIrrDbQvWpMvsSj2xw        3.62                359           79   \n",
       "15  23eqwlZzCWZkADWfd9atZw        3.62                359           79   \n",
       "16  FunI9om-aK5oMIIJmhMlZA        3.62                359           79   \n",
       "17  FKu4iU62EmWT6GZXPJ2sgA        3.62                359           79   \n",
       "18  xdu8nXrbNKeaywCX79KZSw        3.62                359           79   \n",
       "19  K7o5jDInfmX3cY5oH6ATNw        3.62                359           79   \n",
       "20  WYDFJOBOl7cycd7gN-c_xA        3.62                359           79   \n",
       "21  HSR2RLOifd0cvSNVqGXkMQ        3.62                359           79   \n",
       "22  Kki2nwtP8U2qmWwRvPwLRA        3.62                359           79   \n",
       "23  Q-mhDIKa3wJuWEx9uuciIA        3.62                359           79   \n",
       "24  ypjtMQLKdAwKGRS-KU7oxA        3.62                359           79   \n",
       "25  vr9YpzkaVdDIauxiZYZhqA        3.62                359           79   \n",
       "26  Ia-w-nR1FrlzsiuEiqqlbg        3.62                359           79   \n",
       "27  y21Fom8a_SdAyC6I0v554w        3.62                359           79   \n",
       "28  _ku1sDwkmQo2wIgWAaluZw        3.62                359           79   \n",
       "29  Enuk_DJbK0JPmgbFU8ePKw        3.62                359           79   \n",
       "30  iYlepMJ6j4whB8gxiZm6mw        3.62                359           79   \n",
       "31  reeZj98t_X1DrZgQgFs9Kg        3.62                359           79   \n",
       "32  z9e32TaBomM5uY7fHYqYKg        3.62                359           79   \n",
       "33  rQgIiq1FJR8NwBJuWlUn7Q        3.62                359           79   \n",
       "34  7GsVl-wMaSfG1VoEK6-s6g        3.62                359           79   \n",
       "35  zEDdYhDYYfvd8bSQqpc_ww        3.62                359           79   \n",
       "36  b1Volwlw8gt_IGh9PhRQmw        3.62                359           79   \n",
       "37  iFL5Iw972vd09fg87ElP9A        3.62                359           79   \n",
       "38  pREKh8GSMq5UY9CqsnlQUQ        3.62                359           79   \n",
       "39  DcON7DHHHsvl8fByRl41MQ        3.62                359           79   \n",
       "40  sny_ekbd4i_1EBx1gwayXw        3.62                359           79   \n",
       "41  Tv-_7d1sa-6cPTZ20exTLA        3.62                359           79   \n",
       "42  uwp2sAXf5shT1ynRWo7sHg        3.62                359           79   \n",
       "43  gDBVb6Qdg5VAr2L95NEeFw        3.62                359           79   \n",
       "44  Ebggx4Zlc4VWReJMG1nT6w        3.62                359           79   \n",
       "45  Q0j8DFqW_zWNa-H1QuuPgg        3.62                359           79   \n",
       "46  EKAN4jw3LsE3631feSaA_g        3.62                359           79   \n",
       "47  51TLGhFncBnppaBN5vHlcw        3.62                359           79   \n",
       "48  zo84NPvoDgm1W9poSCjPQQ        3.62                359           79   \n",
       "49  0wsN8ZT101c8LhqwQZJjvw        3.62                359           79   \n",
       "\n",
       "    business_stars  business_review_count  unigram  class  \n",
       "0              4.0                   1953      5.0    5.0  \n",
       "1              4.0                     84      5.0    5.0  \n",
       "2              4.5                     50      5.0    5.0  \n",
       "3              4.0                     70      5.0    5.0  \n",
       "4              3.5                     61      4.0    4.0  \n",
       "5              4.5                    397      4.0    4.0  \n",
       "6              4.5                     38      5.0    5.0  \n",
       "7              4.0                    111      4.0    4.0  \n",
       "8              4.0                     64      4.0    4.0  \n",
       "9              3.5                    251      3.0    3.0  \n",
       "10             5.0                      3      5.0    5.0  \n",
       "11             3.5                     35      4.0    4.0  \n",
       "12             3.5                     76      3.0    3.0  \n",
       "13             3.0                      4      1.0    1.0  \n",
       "14             4.0                   1184      3.0    3.0  \n",
       "15             4.0                     48      5.0    5.0  \n",
       "16             4.0                   1953      4.0    4.0  \n",
       "17             1.0                      4      1.0    1.0  \n",
       "18             3.5                     34      3.0    3.0  \n",
       "19             4.0                    418      3.0    3.0  \n",
       "20             3.0                    759      1.0    1.0  \n",
       "21             3.5                    259      3.0    3.0  \n",
       "22             4.0                    135      4.0    4.0  \n",
       "23             3.5                     47      3.0    3.0  \n",
       "24             3.0                     68      1.0    1.0  \n",
       "25             3.5                     14      3.0    3.0  \n",
       "26             3.5                     58      3.0    3.0  \n",
       "27             3.0                     34      2.0    2.0  \n",
       "28             4.0                    511      5.0    5.0  \n",
       "29             4.0                    973      3.0    3.0  \n",
       "30             4.0                     32      4.0    4.0  \n",
       "31             4.0                     36      4.0    4.0  \n",
       "32             2.5                     53      1.0    1.0  \n",
       "33             4.0                    162      4.0    4.0  \n",
       "34             4.5                      5      4.0    4.0  \n",
       "35             4.0                     70      4.0    4.0  \n",
       "36             3.5                      5      5.0    5.0  \n",
       "37             4.0                     53      4.0    4.0  \n",
       "38             4.0                    143      4.0    4.0  \n",
       "39             3.5                     44      4.0    4.0  \n",
       "40             4.0                     16      4.0    4.0  \n",
       "41             4.0                     76      2.0    2.0  \n",
       "42             3.5                     73      4.0    4.0  \n",
       "43             3.5                     34      4.0    4.0  \n",
       "44             2.5                     94      1.0    1.0  \n",
       "45             3.0                    194      1.0    1.0  \n",
       "46             4.0                    443      4.0    4.0  \n",
       "47             4.0                    297      4.0    4.0  \n",
       "48             3.5                     39      4.0    4.0  \n",
       "49             3.5                     37      4.0    4.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset/feature_vectors_10000each.csv')\n",
    "\n",
    "#data['unigram'] = round(data['unigram'],1)\n",
    "#data[data['unigram'] != data['class']]\n",
    "\n",
    "data.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Show the distribution of reviews **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 5 artists>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44e3a40080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "c1 = data[data['class'] == 1].shape[0]\n",
    "c2 = data[data['class'] == 2].shape[0]\n",
    "c3 = data[data['class'] == 3].shape[0]\n",
    "c4 = data[data['class'] == 4].shape[0]\n",
    "c5 = data[data['class'] == 5].shape[0]\n",
    "\n",
    "x = [\"1.0\", \"2.0\", \"3.0\", \"4.0\", \"5.0\"]\n",
    "y = [c1,c2,c3,c4,c5]\n",
    "\n",
    "plt.bar(x,y)\n",
    "#data['class'].plot(kind='kde',style='k--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split our data into training and testing sets **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#data = data.set_index(data['review_id'])\n",
    "\n",
    "X = data[['user_stars','user_review_count','user_useful','business_stars','business_review_count','unigram']]\n",
    "y = data[['class']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Run a linear regression model on the data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error = 1.0564\n",
      "R-squared = 0.4388\n",
      "Root mean squared error = 1.0602\n",
      "R-squared = 0.4443\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression() \n",
    "\n",
    "# Fit regression model to the training set\n",
    "regr.fit( X_train, y_train.values.ravel() )\n",
    "\n",
    "y_train_pred = regr.predict(X_train)\n",
    "\n",
    "# Apply model to the test set\n",
    "y_pred = regr.predict( X_test )\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_train, y_train_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_train, y_train_pred ))\n",
    "\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_test, y_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_test, y_pred ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Run a ridge regression model on the data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error = 1.0564\n",
      "R-squared = 0.4388\n",
      "Root mean squared error = 1.0602\n",
      "R-squared = 0.4443\n",
      "Selected alpha = 1.00\n"
     ]
    }
   ],
   "source": [
    "# Create lasso regression object\n",
    "ridge = linear_model.RidgeCV(cv=5, alphas=[0.01,0.02,0.05,0.1,0.2,0.3,0.5,1.0])\n",
    "\n",
    "# Fit regression model to the training set\n",
    "ridge.fit( X_train, y_train.values.ravel() )\n",
    "\n",
    "y_train_pred = ridge.predict(X_train)\n",
    "\n",
    "# Apply model to the test set\n",
    "y_pred = ridge.predict( X_test )\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_train, y_train_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_train, y_train_pred ))\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_test,y_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_test,y_pred ))\n",
    "print('Selected alpha = %.2f' % ridge.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Run a lasso regression model on the data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error = 1.0565\n",
      "R-squared = 0.4387\n",
      "Root mean squared error = 1.0606\n",
      "R-squared = 0.4439\n",
      "Selected alpha = 0.01\n"
     ]
    }
   ],
   "source": [
    "# Create lasso regression object\n",
    "lasso = linear_model.LassoCV(cv=5, alphas=[0.01,0.02,0.05,0.1,0.2,0.3,0.5,1.0])\n",
    "\n",
    "# Fit regression model to the training set\n",
    "lasso.fit( X_train, y_train.values.ravel() )\n",
    "\n",
    "y_train_pred = lasso.predict(X_train)\n",
    "\n",
    "# Apply model to the test set\n",
    "y_pred = lasso.predict( X_test )\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_train, y_train_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_train, y_train_pred ))\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_test,y_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_test,y_pred ))\n",
    "print('Selected alpha = %.2f' % lasso.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Test the RMSE and R2_score just using the unigram prediction **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error = 1.5279\n",
      "R-squared = -0.1541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "y_unigram_pred = X_test[['unigram']]\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_test,y_unigram_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_test,y_unigram_pred ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Test the RMSE and R2_score of a base case where every review is classified as 5 (the most common class) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error = 2.4520\n",
      "R-squared = -1.9721\n"
     ]
    }
   ],
   "source": [
    "y_test_base = [5 for i in range(len(y_test))]\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_test, y_test_base) ))\n",
    "print('R-squared = %.4f' % r2_score( y_test, y_test_base ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Test the RMSE and R2_score of a base case where every review is classified as the average review score **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error = 1.4223\n",
      "R-squared = -0.0000\n"
     ]
    }
   ],
   "source": [
    "x = 5*(len(data[data['class']==5])/50000)+4*(len(data[data['class']==4])/50000)+3*(len(data[data['class']==3])/50000)+2*(len(data[data['class']==2])/50000)+1*(len(data[data['class']==1])/50000)\n",
    "y_test_base = [x for i in range(len(y_test))]\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_test, y_test_base) ))\n",
    "print('R-squared = %.4f' % r2_score( y_test, y_test_base ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Run a logistic regression classifier on the feature vector **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4220\n",
      "F1 Score = 0.3909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "logistic = linear_model.LogisticRegressionCV(cv= 5 , Cs = [0.01, 0.05, 0.1, 0.5, 1] )\n",
    "logistic.fit( X_train, y_train.values.ravel() )\n",
    "class_pred = logistic.predict( X_test )\n",
    "\n",
    "print('Accuracy = %.4f' % accuracy_score( y_test, class_pred ))\n",
    "print('F1 Score = %.4f' % f1_score( y_test, class_pred, average='weighted' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Determine base classification accuracy by classifying as 5 every time **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base accuracy = 0.2000\n"
     ]
    }
   ],
   "source": [
    "print(\"Base accuracy = %.4f\" % (len(data[data['class']==5])/50000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Determine base classification accuracy by assigning a random class based on the probability distribution of our data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.1988\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "y_base_class = []\n",
    "pred5 = 100 - (len(data[data['class']==5])/20000)*100\n",
    "pred4 = pred5 - (len(data[data['class']==4])/20000)*100\n",
    "pred3 = pred4 - (len(data[data['class']==3])/20000)*100\n",
    "pred2 = pred3 - (len(data[data['class']==2])/20000)*100\n",
    "pred1 = pred2 - (len(data[data['class']==1])/20000)*100\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    x=randint(0, 100)\n",
    "    if x > pred5:\n",
    "        y_base_class.append(5)\n",
    "    elif x > pred4:\n",
    "        y_base_class.append(4)\n",
    "    elif x > pred3:\n",
    "        y_base_class.append(3)\n",
    "    elif x > pred2:\n",
    "        y_base_class.append(2)\n",
    "    else:\n",
    "        y_base_class.append(1)\n",
    "        \n",
    "print('Accuracy = %.4f' % accuracy_score( y_test, y_base_class ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Re-train the model by classifying reviews as \"good\" (1) or \"bad\" (0) instead of making a unigram prediction **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "X_train_copy = copy.deepcopy(X_train)\n",
    "X_test_copy = copy.deepcopy(X_test)\n",
    "\n",
    "X_train['unigram'] = [1 if point >= 2.5 else 0 for point in X_train_copy['unigram']]\n",
    "X_test['unigram'] = [1 if point >= 2.5 else 0 for point in X_test_copy['unigram']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error = 1.0715\n",
      "R-squared = 0.4226\n",
      "Root mean squared error = 1.0730\n",
      "R-squared = 0.4309\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression() \n",
    "\n",
    "# Fit regression model to the training set\n",
    "regr.fit( X_train, y_train.values.ravel() )\n",
    "\n",
    "y_train_pred = regr.predict(X_train)\n",
    "\n",
    "# Apply model to the test set\n",
    "y_pred = regr.predict( X_test )\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_train, y_train_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_train, y_train_pred ))\n",
    "\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_test, y_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_test, y_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error = 1.0715\n",
      "R-squared = 0.4226\n",
      "Root mean squared error = 1.0730\n",
      "R-squared = 0.4309\n",
      "Selected alpha = 1.00\n"
     ]
    }
   ],
   "source": [
    "# Create lasso regression object\n",
    "ridge = linear_model.RidgeCV(cv=5, alphas=[0.01,0.02,0.05,0.1,0.2,0.3,0.5,1.0])\n",
    "\n",
    "# Fit regression model to the training set\n",
    "ridge.fit( X_train, y_train.values.ravel() )\n",
    "\n",
    "y_train_pred = ridge.predict(X_train)\n",
    "\n",
    "# Apply model to the test set\n",
    "y_pred = ridge.predict( X_test )\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_train, y_train_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_train, y_train_pred ))\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_test,y_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_test,y_pred ))\n",
    "print('Selected alpha = %.2f' % ridge.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error = 1.0715\n",
      "R-squared = 0.4226\n",
      "Root mean squared error = 1.0735\n",
      "R-squared = 0.4304\n",
      "Selected alpha = 0.01\n"
     ]
    }
   ],
   "source": [
    "# Create lasso regression object\n",
    "lasso = linear_model.LassoCV(cv=5, alphas=[0.01,0.02,0.05,0.1,0.2,0.3,0.5,1.0])\n",
    "\n",
    "# Fit regression model to the training set\n",
    "lasso.fit( X_train, y_train.values.ravel() )\n",
    "\n",
    "y_train_pred = regr.predict(X_train)\n",
    "\n",
    "# Apply model to the test set\n",
    "y_pred = lasso.predict( X_test )\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_train, y_train_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_train, y_train_pred ))\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_test,y_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_test,y_pred ))\n",
    "print('Selected alpha = %.2f' % lasso.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4184\n",
      "F1 Score = 0.3844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "logistic = linear_model.LogisticRegressionCV(cv= 5 , Cs = [0.01, 0.05, 0.1, 0.5, 1] )\n",
    "logistic.fit( X_train, y_train.values.ravel() )\n",
    "class_pred = logistic.predict( X_test )\n",
    "\n",
    "print('Accuracy = %.4f' % accuracy_score( y_test, class_pred ))\n",
    "print('F1 Score = %.4f' % f1_score( y_test, class_pred, average='weighted' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-train the model by classifying reviews as \"good\" (2), \"medium\" (1) or \"bad\" (0) instead of making a unigram prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_stars</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>user_useful</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>business_review_count</th>\n",
       "      <th>unigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12741</th>\n",
       "      <td>2.39</td>\n",
       "      <td>490</td>\n",
       "      <td>175</td>\n",
       "      <td>3.0</td>\n",
       "      <td>340</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18005</th>\n",
       "      <td>3.59</td>\n",
       "      <td>77</td>\n",
       "      <td>116</td>\n",
       "      <td>4.5</td>\n",
       "      <td>686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36729</th>\n",
       "      <td>3.38</td>\n",
       "      <td>91</td>\n",
       "      <td>44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48571</th>\n",
       "      <td>4.23</td>\n",
       "      <td>132</td>\n",
       "      <td>31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25464</th>\n",
       "      <td>3.47</td>\n",
       "      <td>13</td>\n",
       "      <td>79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_stars  user_review_count  user_useful  business_stars  \\\n",
       "12741        2.39                490          175             3.0   \n",
       "18005        3.59                 77          116             4.5   \n",
       "36729        3.38                 91           44             3.0   \n",
       "48571        4.23                132           31             4.0   \n",
       "25464        3.47                 13           79             4.0   \n",
       "\n",
       "       business_review_count  unigram  \n",
       "12741                    340        2  \n",
       "18005                    686        1  \n",
       "36729                     41        0  \n",
       "48571                   2291        0  \n",
       "25464                    177        2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "X_train['unigram'] = [2 if point > 3.1 else 1 if point > 2.1 else 0 for point in X_train_copy['unigram']]\n",
    "X_test['unigram'] = [2 if point > 3.1 else 1 if point > 2.1 else 0 for point in X_test_copy['unigram']]\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error = 1.0612\n",
      "R-squared = 0.4337\n",
      "Root mean squared error = 1.0632\n",
      "R-squared = 0.4411\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression() \n",
    "\n",
    "# Fit regression model to the training set\n",
    "regr.fit( X_train, y_train.values.ravel() )\n",
    "\n",
    "y_train_pred = regr.predict(X_train)\n",
    "\n",
    "# Apply model to the test set\n",
    "y_pred = regr.predict( X_test )\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_train, y_train_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_train, y_train_pred ))\n",
    "\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_test, y_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_test, y_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error = 1.0612\n",
      "R-squared = 0.4337\n",
      "Root mean squared error = 1.0632\n",
      "R-squared = 0.4411\n",
      "Selected alpha = 1.00\n"
     ]
    }
   ],
   "source": [
    "# Create lasso regression object\n",
    "ridge = linear_model.RidgeCV(cv=5, alphas=[0.01,0.02,0.05,0.1,0.2,0.3,0.5,1.0])\n",
    "\n",
    "# Fit regression model to the training set\n",
    "ridge.fit( X_train, y_train.values.ravel() )\n",
    "\n",
    "y_train_pred = ridge.predict(X_train)\n",
    "\n",
    "# Apply model to the test set\n",
    "y_pred = ridge.predict( X_test )\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_train, y_train_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_train, y_train_pred ))\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_test,y_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_test,y_pred ))\n",
    "print('Selected alpha = %.2f' % ridge.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error = 1.0612\n",
      "R-squared = 0.4337\n",
      "Root mean squared error = 1.0637\n",
      "R-squared = 0.4407\n",
      "Selected alpha = 0.01\n"
     ]
    }
   ],
   "source": [
    "# Create lasso regression object\n",
    "lasso = linear_model.LassoCV(cv=5, alphas=[0.01,0.02,0.05,0.1,0.2,0.3,0.5,1.0])\n",
    "\n",
    "# Fit regression model to the training set\n",
    "lasso.fit( X_train, y_train.values.ravel() )\n",
    "\n",
    "y_train_pred = regr.predict(X_train)\n",
    "\n",
    "# Apply model to the test set\n",
    "y_pred = lasso.predict( X_test )\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_train, y_train_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_train, y_train_pred ))\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt( mean_squared_error(y_test,y_pred) ))\n",
    "print('R-squared = %.4f' % r2_score( y_test,y_pred ))\n",
    "print('Selected alpha = %.2f' % lasso.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4230\n",
      "F1 Score = 0.3932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "logistic = linear_model.LogisticRegressionCV(cv= 5 , Cs = [0.01, 0.05, 0.1, 0.5, 1] )\n",
    "logistic.fit( X_train, y_train.values.ravel() )\n",
    "class_pred = logistic.predict( X_test )\n",
    "\n",
    "print('Accuracy = %.4f' % accuracy_score( y_test, class_pred ))\n",
    "print('F1 Score = %.4f' % f1_score( y_test, class_pred, average='weighted' ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
